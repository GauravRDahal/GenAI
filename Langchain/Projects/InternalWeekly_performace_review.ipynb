{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSxHhc6WUdhC",
        "outputId": "38c6915f-8802-4bd2-feb6-b65a8865a7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.299-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
            "  Downloading langsmith-0.0.40-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Collecting huggingface_hub<0.17,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=3bd30469c237368713966729dd30b9bbe90f958c5476fb734c1bdcccdfd7d56b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, python-dotenv, pulsar-client, overrides, mypy-extensions, marshmallow, jsonpointer, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, langsmith, jsonpatch, huggingface_hub, coloredlogs, tokenizers, openai, onnxruntime, fastapi, dataclasses-json, langchain, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 coloredlogs-15.0.1 dataclasses-json-0.6.0 fastapi-0.99.1 h11-0.14.0 httptools-0.6.0 huggingface_hub-0.16.4 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.299 langsmith-0.0.40 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.16.0 openai-0.28.0 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.14.0 typing-inspect-0.9.0 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain tiktoken chromadb\n",
        "# https://python.langchain.com/docs/integrations/llms/llm_caching\n",
        "# https://www.linkedin.com/pulse/how-cache-llm-calls-using-langchain-suman-mishra/\n",
        "# importing all the dependencies\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
        "from langchain.cache import InMemoryCache, SQLiteCache\n",
        "import langchain\n",
        "import chromadb\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "import os\n",
        "#langchain.llm_cache = InMemoryCache()\n",
        "#langchain.llm_cache = SQLiteCache(database_path= \"langchain.db\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "#### IMPORT BOTH FILES BEFORE RUNNING THIS CELL ##########\n",
        "##########################################################\n",
        "\n",
        "# --- Step 1 ---\n",
        "f = open(\"/content/api_key.txt\")\n",
        "api_key = f.read()\n",
        "chat = ChatOpenAI(openai_api_key=api_key, temperature=0)\n",
        "\n",
        "# --- Step 2 ---\n",
        "df = pd.read_csv(\"/content/sdlms_dev.performance_reviews.csv\")\n",
        "len_entries = len(df)\n",
        "\n",
        "#print(\"\\n\")\n",
        "print(f\"Total number of entries : {len_entries} unicorns\")\n",
        "print(\"=====================================\")\n",
        "df[\"name\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPEA7MG7Uews",
        "outputId": "e82e9e12-5584-4990-df41-0bab1ba09d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of entries : 10 unicorns\n",
            "=====================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        Angad\n",
              "1                 Gaurav Dahal\n",
              "2                  Anaya Sutar\n",
              "3                prajesheleven\n",
              "4                   Gowthami 0\n",
              "5    TARUGU UMA MAHESWAR REDDY\n",
              "6                 Fardin Kamal\n",
              "7                Samidha Kumar\n",
              "8               Hinglaj Tanwar\n",
              "9                  Artuha Paul\n",
              "Name: name, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weekly_report(x):\n",
        "\n",
        "  # dependencies\n",
        "  langchain.llm_cache = SQLiteCache(database_path= \"langchain.db\")\n",
        "\n",
        "  question_list = [\n",
        "  \"How would you quantify your contributions (of ...\",\n",
        "  \"What are the expected figures?\",\n",
        "  \"What are the actual figures?\",\n",
        "  \"Did you understand how your project lead quant...\",\n",
        "  \"What bottlenecks are slowing you down?\",\n",
        "  \"Why do you think you're facing this bottleneck?\",\n",
        "  \"Would you like to create a process to solve th...\",\n",
        "  \"What are your milestones for the next week?\",\n",
        "  \"Why have you set these milestones?\",\n",
        "  \"How are you improving the quality and quantity...\",\n",
        "  \"How do you plan to achieve these milestones?\",\n",
        "  \"How are you assessing your work?\",\n",
        "  \"Do you rely on senior feedback or do you have ...\",\n",
        "  \"If your project has a long gestation period an...\",\n",
        "  ]\n",
        "\n",
        "  # setting up data points\n",
        "  candidiate_fact_sheet = df.iloc[x]\n",
        "  answers = candidiate_fact_sheet[3:-6]\n",
        "  deliverables = candidiate_fact_sheet[4:6]\n",
        "  name = candidiate_fact_sheet[1]\n",
        "  questions_d = question_list[1:3]\n",
        "  name = df['name'][x]\n",
        "  team = df['departmentName'][x]\n",
        "\n",
        "  # for bottlenecks\n",
        "  template_string = \"\"\"Based on the {name}, the intern's performance review \\\n",
        "  raise only 3-4 serious red-flags in bullet-points \\\n",
        "  using the question's list to the answers.\\nQuestions:{question_list}\\nAnswers:{answers} \\\n",
        "  Do not mentions questions in the summary.\n",
        "  Raise atmost 4 red-flags.\n",
        "  \"\"\"\n",
        "  prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "  summary = prompt_template.format_messages(name = name,\n",
        "                                            answers = answers,\n",
        "                                            question_list = question_list\n",
        "                                            )\n",
        "  response = chat(summary)\n",
        "\n",
        "  # for deliverables\n",
        "  template_string_d = \"\"\"Based on the {name}, the intern's performance review \\\n",
        "  raise only 3-4  bullet-points \\\n",
        "  using the question's list to the answers.\\nQuestions:{question_list}\\nAnswers:{answers} \\\n",
        "  Swap 'expected figures' with 'expected numbers' and 'actual figures' with 'actual nmbers'. \\\n",
        "  Do not mentions questions.\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_template_d = ChatPromptTemplate.from_template(template_string_d)\n",
        "  summary_d = prompt_template.format_messages(name = name,\n",
        "                                            answers = deliverables,\n",
        "                                            question_list = questions_d\n",
        "                                            )\n",
        "  response_d = chat(summary_d)\n",
        "\n",
        "  # SequentialChain\n",
        "  template1 = \"Give a summary of an intern's performance review\\n{review}\"\n",
        "  prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "  chain1 = LLMChain(llm=chat, prompt = prompt1, output_key=\"review_summary\")\n",
        "  template2 = \"Identify Key employee weakness in this review summary\\n{review_summary}\"\n",
        "  prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "  chain2 = LLMChain(llm=chat, prompt = prompt2, output_key=\"weaknesses\")\n",
        "  template3 = \"Create a personalized plan 'Personalized Plan to Address and Fix Key Employee Weaknesses:' to help address and fix these weaknesses with at most 4 pointers.\\n{weaknesses}\"\n",
        "  prompt3 = ChatPromptTemplate.from_template(template3)\n",
        "  chain3 = LLMChain(llm=chat, prompt = prompt3, output_key=\"final_plan\")\n",
        "\n",
        "  # Setting up SequentialChains\n",
        "  seq_chain = SequentialChain(chains=[chain1, chain2, chain3],\n",
        "                              input_variables=[\"review\"],\n",
        "                              output_variables=[\"review_summary\", \"weaknesses\", \"final_plan\"],\n",
        "                              verbose=False)\n",
        "  results = seq_chain(candidiate_fact_sheet)\n",
        "  print(\"WEEKLY REPORT:\")\n",
        "  print(\"________\")\n",
        "  print(f\"Name = {name}\\n\")\n",
        "  print(f\"Team = {team}\")\n",
        "  print(\"\\n\")\n",
        "  print(\"Summary:\")\n",
        "  print(results['review_summary'])\n",
        "  print(\"\\n\")\n",
        "  print(\"Deliverables:\")\n",
        "  print(\"______\")\n",
        "  print(\"NOTE: Here 'actual figures' represent 'actual numbers' and 'expected figures' represents 'expected numbers'.\")\n",
        "  print(response_d.content)\n",
        "  print(\"\\n\")\n",
        "  print(\"Bottlenecks:\")\n",
        "  print(response.content)\n",
        "  print(\"\\n\")\n",
        "  print(\"Suggestions\")\n",
        "  print(results[\"final_plan\"])"
      ],
      "metadata": {
        "id": "TyJLmgumvDsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weekly_report(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BydKQmivD3K",
        "outputId": "dbeb3404-9c94-45ef-dce5-6458b00b0e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WEEKLY REPORT:\n",
            "---------------\n",
            "Name = Gowthami 0\n",
            "\n",
            "Team = Career Acceleration Lab\n",
            "\n",
            "\n",
            "Summary:\n",
            "The intern, Gowthami 0, has shown good performance in their role. They have successfully come up with 5 data points for the LPS index and have developed a method to quantify the index. They have faced difficulties in understanding the progress of the project, but this bottleneck is considered intrinsic. They have tried to go through all the relevant links and have focused on the DTthon courses to understand the team's objectives. They have been completing the most prioritized tasks and have been reviewing their progress with the team. They have been documenting the process and progress and have observable metrics to assess their performance. They are also documenting the reasonings behind long-gestation tasks. The performance review was conducted during the week of August 14th to August 20th, 2023.\n",
            "\n",
            "\n",
            "Deliverables:\n",
            "---------------\n",
            "NOTE: Here 'actual figures' represent 'actual numbers' and 'expected figures' represents 'expected numbers'.\n",
            "- The intern's performance in completing the LPS Index is below expectations.\n",
            "- The intern's method to quantify the figures is not satisfactory.\n",
            "- The intern's actual figures do not meet the expected figures.\n",
            "\n",
            "\n",
            "Bottlenecks:\n",
            "1. The intern had difficulties in understanding the progress of the project, indicating a potential lack of clarity or communication.\n",
            "2. The intern mentioned facing a bottleneck that is intrinsic, suggesting a potential issue with their skills or knowledge in that area.\n",
            "3. The intern mentioned relying on senior feedback and observable metrics, indicating a potential lack of independent assessment or self-evaluation.\n",
            "4. The intern mentioned focusing on DTthon courses for milestones, which may not align with the team's objectives or project goals.\n",
            "\n",
            "\n",
            "Suggestions\n",
            "Personalized Plan to Address and Fix Key Employee Weaknesses: Difficulty in Understanding Project Progress\n",
            "\n",
            "1. Clear Communication Channels: Establish clear and open lines of communication between the key employee and project stakeholders. This can be achieved by implementing regular progress meetings, where the employee can ask questions and receive updates on the project's status. Encourage the employee to actively participate in these meetings and provide feedback to ensure a better understanding of the project progress.\n",
            "\n",
            "2. Training and Development: Offer training and development opportunities to enhance the employee's project management skills. This can include workshops or courses on project management methodologies, tools, and techniques. By improving their knowledge and skills in project management, the employee will be better equipped to understand and track project progress effectively.\n",
            "\n",
            "3. Visual Project Tracking: Implement visual project tracking tools or software that provide real-time updates on project progress. This can include Gantt charts, Kanban boards, or project management software with progress tracking features. Encourage the employee to utilize these tools to visualize the project's timeline, tasks, and milestones, enabling them to have a clearer understanding of the project's progress.\n",
            "\n",
            "4. Mentorship and Guidance: Assign a mentor or supervisor to provide guidance and support to the key employee. This mentor can be an experienced project manager who can help the employee navigate through project complexities and provide insights on tracking progress effectively. Regular check-ins with the mentor can help address any concerns or questions the employee may have, ensuring a better understanding of the project's progress.\n",
            "\n",
            "By implementing these four pointers, the key employee will have the necessary tools, knowledge, and support to address and fix their difficulty in understanding project progress. This personalized plan aims to enhance their project management skills, improve communication, and provide visual aids to ensure a clearer understanding of the project's progress.\n"
          ]
        }
      ]
    }
  ]
}